{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39ce1f11",
   "metadata": {},
   "source": [
    "## Preprocessing:\n",
    "> Determine if there's a need for preprocessing steps such as normalization or standardization.\n",
    "\n",
    "> Handle missing data appropriately, either by imputation or removal.\n",
    "\n",
    "## Data Splitting:\n",
    "> Split your dataset into training and validation sets. This is crucial for evaluating the performance of your model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba9920f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/macalester/.local/lib/python3.10/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "2024-01-15 12:52:01.782580: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-15 12:52:01.812608: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-15 12:52:01.812633: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-15 12:52:01.813402: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-15 12:52:01.818431: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-15 12:52:02.494886: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob\n",
    "import PIL\n",
    "from PIL import Image, ImageOps\n",
    "import shutil\n",
    "from skimage import data\n",
    "from skimage.util import montage \n",
    "import skimage.transform as skTrans\n",
    "from skimage.transform import rotate\n",
    "from skimage.transform import resize\n",
    "from PIL import Image, ImageOps  \n",
    "import nilearn as nl\n",
    "import nibabel as nib\n",
    "import nilearn.plotting as nlplt\n",
    "import gif_your_nifti.core as gif2nif\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.callbacks import CSVLogger\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff299a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE seg-areas  \n",
    "SEGMENT_CLASSES = {\n",
    "    0 : 'NOT tumor',\n",
    "    1 : 'NECROTIC/CORE', # or NON-ENHANCING tumor CORE\n",
    "    2 : 'EDEMA',\n",
    "    3 : 'ENHANCING' # original 4 -> converted into 3 later\n",
    "}\n",
    "\n",
    "# there are 155 slices per volume\n",
    "# to start at 5 and use 145 slices means we will skip the first 5 and last 5 \n",
    "VOLUME_SLICES = 100 \n",
    "VOLUME_START_AT = 22 # first slice of volume that we will include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f69f83f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"../data/segData/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c316767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/rastislav/3d-mri-brain-tumor-segmentation-u-net\n",
    "# dice loss idea refernce from website above\n",
    "def dice_coef(y_real, y_pred, smooth = 1.0):\n",
    "    class_num = 4\n",
    "    for i in range(class_num):\n",
    "        y_real_flatten = K.flatten(y_true[:,:,:,i])\n",
    "        y_pred_flatten = K.flatten(y_pred[:,:,:,i])\n",
    "        intersection = K.sum(y_real_flatten * y_pred_flatten)\n",
    "        loss = ((2. * intersection + smooth) / (K.sum(y_real_flatten) + K.sum(y_pred_flatten) + smooth))\n",
    "        if i == 0:\n",
    "            total_loss = loss\n",
    "        else:\n",
    "            total_loss = total_loss + loss\n",
    "    total_loss = total_loss / class_num\n",
    "    return total_loss\n",
    "\n",
    "# define per class evaluation of dice coef\n",
    "# inspired by https://github.com/keras-team/keras/issues/9395\n",
    "def dice_coef_necrotic(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[:,:,:,1] * y_pred[:,:,:,1]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,1])) + K.sum(K.square(y_pred[:,:,:,1])) + epsilon)\n",
    "\n",
    "def dice_coef_edema(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[:,:,:,2] * y_pred[:,:,:,2]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,2])) + K.sum(K.square(y_pred[:,:,:,2])) + epsilon)\n",
    "\n",
    "def dice_coef_enhancing(y_true, y_pred, epsilon=1e-6):\n",
    "    intersection = K.sum(K.abs(y_true[:,:,:,3] * y_pred[:,:,:,3]))\n",
    "    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,3])) + K.sum(K.square(y_pred[:,:,:,3])) + epsilon)\n",
    "\n",
    "# Computing Precision \n",
    "def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    \n",
    "# Computing Sensitivity      \n",
    "def sensitivity(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "\n",
    "# Computing Specificity\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88b7c5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52c8be0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# benchmark model\n",
    "def Unet3D(inputs,num_classes):\n",
    "    x=inputs\n",
    "    conv1 = Conv3D(8, 3, activation = 'relu', padding = 'same',data_format=\"channels_last\")(x)\n",
    "    conv1 = Conv3D(8, 3, activation = 'relu', padding = 'same')(conv1)\n",
    "    pool1 = MaxPooling3D(pool_size=(2, 2, 2))(conv1)\n",
    "    conv2 = Conv3D(16, 3, activation = 'relu', padding = 'same')(pool1)\n",
    "    conv2 = Conv3D(16, 3, activation = 'relu', padding = 'same')(conv2)\n",
    "    pool2 = MaxPooling3D(pool_size=(2, 2, 2))(conv2)\n",
    "    conv3 = Conv3D(32, 3, activation = 'relu', padding = 'same')(pool2)\n",
    "    conv3 = Conv3D(32, 3, activation = 'relu', padding = 'same')(conv3)\n",
    "    pool3 = MaxPooling3D(pool_size=(2, 2, 2))(conv3)\n",
    "    conv4 = Conv3D(64, 3, activation = 'relu', padding = 'same')(pool3)\n",
    "    conv4 = Conv3D(64, 3, activation = 'relu', padding = 'same')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling3D(pool_size=(2, 2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv3D(128, 3, activation = 'relu', padding = 'same')(pool4)\n",
    "    conv5 = Conv3D(128, 3, activation = 'relu', padding = 'same')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv3D(64, 2, activation = 'relu', padding = 'same')(UpSampling3D(size = (2,2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6],axis=-1)\n",
    "    conv6 = Conv3D(64, 3, activation = 'relu', padding = 'same')(merge6)\n",
    "    conv6 = Conv3D(64, 3, activation = 'relu', padding = 'same')(conv6)\n",
    "\n",
    "    up7 = Conv3D(32, 2, activation = 'relu', padding = 'same')(UpSampling3D(size = (2,2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7],axis=-1)\n",
    "    conv7 = Conv3D(32, 3, activation = 'relu', padding = 'same')(merge7)\n",
    "    conv7 = Conv3D(32, 3, activation = 'relu', padding = 'same')(conv7)\n",
    "\n",
    "    up8 = Conv3D(16, 2, activation = 'relu', padding = 'same')(UpSampling3D(size = (2,2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8],axis=-1)\n",
    "    conv8 = Conv3D(16, 3, activation = 'relu', padding = 'same')(merge8)\n",
    "    conv8 = Conv3D(16, 3, activation = 'relu', padding = 'same')(conv8)\n",
    "\n",
    "    up9 = Conv3D(8, 2, activation = 'relu', padding = 'same')(UpSampling3D(size = (2,2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9],axis=-1)\n",
    "    conv9 = Conv3D(8, 3, activation = 'relu', padding = 'same')(merge9)\n",
    "    conv9 = Conv3D(8, 3, activation = 'relu', padding = 'same')(conv9)\n",
    "    conv10 = Conv3D(1, 1, activation = 'sigmoid')(conv9)\n",
    "    model = Model(inputs=inputs, outputs = conv10)\n",
    "    #model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0a626d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Bad StatusOr access: INTERNAL: failed initializing StreamExecutor for CUDA device ordinal 0: INTERNAL: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OUT_OF_MEMORY: out of memory; total memory reported: 16908746752",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 51\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Model(inputs \u001b[38;5;241m=\u001b[39m inputs, outputs \u001b[38;5;241m=\u001b[39m conv10)\n\u001b[1;32m     49\u001b[0m input_layer \u001b[38;5;241m=\u001b[39m Input((IMG_SIZE, IMG_SIZE, \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m---> 51\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_unet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhe_normal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m), metrics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mMeanIoU(num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema ,dice_coef_enhancing] )\n",
      "Cell \u001b[0;32mIn [13], line 4\u001b[0m, in \u001b[0;36mbuild_unet\u001b[0;34m(inputs, ker_init, dropout)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_unet\u001b[39m(inputs, ker_init, dropout):\n\u001b[0;32m----> 4\u001b[0m     conv1 \u001b[38;5;241m=\u001b[39m \u001b[43mConv2D\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_initializer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mker_init\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     conv1 \u001b[38;5;241m=\u001b[39m Conv2D(\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m3\u001b[39m, activation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, padding \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, kernel_initializer \u001b[38;5;241m=\u001b[39m ker_init)(conv1)\n\u001b[1;32m      7\u001b[0m     pool \u001b[38;5;241m=\u001b[39m MaxPooling2D(pool_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m))(conv1)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/backend.py:2142\u001b[0m, in \u001b[0;36mRandomGenerator.truncated_normal\u001b[0;34m(self, shape, mean, stddev, dtype, nonce)\u001b[0m\n\u001b[1;32m   2140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nonce:\n\u001b[1;32m   2141\u001b[0m         seed \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mstateless_fold_in(seed, nonce)\n\u001b[0;32m-> 2142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstateless_truncated_normal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstddev\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstddev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\n\u001b[1;32m   2144\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mtruncated_normal(\n\u001b[1;32m   2146\u001b[0m     shape\u001b[38;5;241m=\u001b[39mshape,\n\u001b[1;32m   2147\u001b[0m     mean\u001b[38;5;241m=\u001b[39mmean,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2150\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_legacy_seed(),\n\u001b[1;32m   2151\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Bad StatusOr access: INTERNAL: failed initializing StreamExecutor for CUDA device ordinal 0: INTERNAL: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OUT_OF_MEMORY: out of memory; total memory reported: 16908746752"
     ]
    }
   ],
   "source": [
    "# source https://naomi-fridman.medium.com/multi-class-image-segmentation-a5cc671e647a\n",
    "\n",
    "def build_unet(inputs, ker_init, dropout):\n",
    "    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(inputs)\n",
    "    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv1)\n",
    "    \n",
    "    pool = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool)\n",
    "    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)\n",
    "    \n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv2)\n",
    "    \n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv3)\n",
    "    \n",
    "    \n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool4)\n",
    "    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv5)\n",
    "    drop5 = Dropout(dropout)(conv5)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv9)\n",
    "    \n",
    "    up = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv9))\n",
    "    merge = concatenate([conv1,up], axis = 3)\n",
    "    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge)\n",
    "    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)\n",
    "    \n",
    "    conv10 = Conv2D(4, (1,1), activation = 'softmax')(conv)\n",
    "    \n",
    "    return Model(inputs = inputs, outputs = conv10)\n",
    "\n",
    "input_layer = Input((IMG_SIZE, IMG_SIZE, 2))\n",
    "\n",
    "model = build_unet(input_layer, 'he_normal', 0.2)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema ,dice_coef_enhancing] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca6b828",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, \n",
    "           show_shapes = True,\n",
    "           show_dtype=False,\n",
    "           show_layer_names = True, \n",
    "           rankdir = 'TB', \n",
    "           expand_nested = False, \n",
    "           dpi = 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35cd6712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists of directories with studies\n",
    "train_and_val_directories = [f.path for f in os.scandir(train_data_path) if f.is_dir()]\n",
    "\n",
    "# file BraTS20_Training_355 has ill formatted name for for seg.nii file\n",
    "train_and_val_directories.remove(train_data_path+'BraTS20_Training_355')\n",
    "\n",
    "\n",
    "def pathListIntoIds(dirList):\n",
    "    x = []\n",
    "    for i in range(0,len(dirList)):\n",
    "        x.append(dirList[i][dirList[i].rfind('/')+1:])\n",
    "    return x\n",
    "\n",
    "train_and_test_ids = pathListIntoIds(train_and_val_directories)\n",
    "\n",
    "    \n",
    "train_test_ids, val_ids = train_test_split(train_and_test_ids,test_size=0.2) \n",
    "train_ids, test_ids = train_test_split(train_test_ids,test_size=0.15) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "403bfccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, dim=(IMG_SIZE,IMG_SIZE), batch_size = 1, n_channels = 2, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        Batch_ids = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(Batch_ids)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, Batch_ids):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, self.n_channels))\n",
    "        y = np.zeros((self.batch_size*VOLUME_SLICES, 240, 240))\n",
    "        Y = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, 4))\n",
    "\n",
    "        \n",
    "        # Generate data\n",
    "        for c, i in enumerate(Batch_ids):\n",
    "            case_path = os.path.join(TRAIN_DATASET_PATH, i)\n",
    "\n",
    "            data_path = os.path.join(case_path, f'{i}_flair.nii');\n",
    "            flair = nib.load(data_path).get_fdata()    \n",
    "\n",
    "            data_path = os.path.join(case_path, f'{i}_t1ce.nii');\n",
    "            ce = nib.load(data_path).get_fdata()\n",
    "            \n",
    "            data_path = os.path.join(case_path, f'{i}_seg.nii');\n",
    "            seg = nib.load(data_path).get_fdata()\n",
    "        \n",
    "            for j in range(VOLUME_SLICES):\n",
    "                 X[j +VOLUME_SLICES*c,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n",
    "                 X[j +VOLUME_SLICES*c,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n",
    "\n",
    "                 y[j +VOLUME_SLICES*c] = seg[:,:,j+VOLUME_START_AT];\n",
    "                    \n",
    "        # Generate masks\n",
    "        y[y==4] = 3;\n",
    "        mask = tf.one_hot(y, 4);\n",
    "        Y = tf.image.resize(mask, (IMG_SIZE, IMG_SIZE));\n",
    "        return X/np.max(X), Y\n",
    "        \n",
    "training_generator = DataGenerator(train_ids)\n",
    "valid_generator = DataGenerator(val_ids)\n",
    "test_generator = DataGenerator(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a27a373",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show number of data for each dir \n",
    "def showDataLayout():\n",
    "    plt.bar([\"Train\",\"Valid\",\"Test\"],\n",
    "    [len(train_ids), len(val_ids), len(test_ids)], align='center',color=[ 'green','red', 'blue'])\n",
    "    plt.legend()\n",
    "\n",
    "    plt.ylabel('Number of images')\n",
    "    plt.title('Data distribution')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "showDataLayout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5dcad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = CSVLogger('training.log', separator=',', append=False)\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "#     keras.callbacks.EarlyStopping(monitor='loss', min_delta=0,\n",
    "#                               patience=2, verbose=1, mode='auto'),\n",
    "      keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=2, min_lr=0.000001, verbose=1),\n",
    "    keras.callbacks.ModelCheckpoint(filepath = 'model_.{epoch:02d}-{val_loss:.6f}.m5',\n",
    "                            verbose=1, save_best_only=True, save_weights_only = True),\n",
    "        csv_logger\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e2fd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "history =  model.fit(training_generator,\n",
    "                    epochs=35,\n",
    "                    steps_per_epoch=len(train_ids),\n",
    "                    callbacks= callbacks,\n",
    "                    validation_data = valid_generator\n",
    "                    )  \n",
    "model.save(\"segementation.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d31b2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ load trained model ################\n",
    "model = keras.models.load_model('../input/modelperclasseval/model_per_class.h5', \n",
    "                                   custom_objects={ 'accuracy' : tf.keras.metrics.MeanIoU(num_classes=4),\n",
    "                                                   \"dice_coef\": dice_coef,\n",
    "                                                   \"precision\": precision,\n",
    "                                                   \"sensitivity\":sensitivity,\n",
    "                                                   \"specificity\":specificity,\n",
    "                                                   \"dice_coef_necrotic\": dice_coef_necrotic,\n",
    "                                                   \"dice_coef_edema\": dice_coef_edema,\n",
    "                                                   \"dice_coef_enhancing\": dice_coef_enhancing\n",
    "                                                  }, compile=False)\n",
    "\n",
    "history = pd.read_csv('../input/modelperclasseval/training_per_class.log', sep=',', engine='python')\n",
    "\n",
    "hist=history\n",
    "\n",
    "############### ########## ####### #######\n",
    "\n",
    "# hist=history.history\n",
    "\n",
    "acc=hist['accuracy']\n",
    "val_acc=hist['val_accuracy']\n",
    "\n",
    "epoch=range(len(acc))\n",
    "\n",
    "loss=hist['loss']\n",
    "val_loss=hist['val_loss']\n",
    "\n",
    "train_dice=hist['dice_coef']\n",
    "val_dice=hist['val_dice_coef']\n",
    "\n",
    "f,ax=plt.subplots(1,4,figsize=(16,8))\n",
    "\n",
    "ax[0].plot(epoch,acc,'b',label='Training Accuracy')\n",
    "ax[0].plot(epoch,val_acc,'r',label='Validation Accuracy')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(epoch,loss,'b',label='Training Loss')\n",
    "ax[1].plot(epoch,val_loss,'r',label='Validation Loss')\n",
    "ax[1].legend()\n",
    "\n",
    "ax[2].plot(epoch,train_dice,'b',label='Training dice coef')\n",
    "ax[2].plot(epoch,val_dice,'r',label='Validation dice coef')\n",
    "ax[2].legend()\n",
    "\n",
    "ax[3].plot(epoch,hist['mean_io_u'],'b',label='Training mean IOU')\n",
    "ax[3].plot(epoch,hist['val_mean_io_u'],'r',label='Validation mean IOU')\n",
    "ax[3].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac67eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictByPath(case_path,case):\n",
    "    files = next(os.walk(case_path))[2]\n",
    "    X = np.empty((VOLUME_SLICES, IMG_SIZE, IMG_SIZE, 2))\n",
    "  #  y = np.empty((VOLUME_SLICES, IMG_SIZE, IMG_SIZE))\n",
    "    \n",
    "    vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_flair.nii');\n",
    "    flair=nib.load(vol_path).get_fdata()\n",
    "    \n",
    "    vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_t1ce.nii');\n",
    "    ce=nib.load(vol_path).get_fdata() \n",
    "    \n",
    " #   vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_seg.nii');\n",
    " #   seg=nib.load(vol_path).get_fdata()  \n",
    "\n",
    "    \n",
    "    for j in range(VOLUME_SLICES):\n",
    "        X[j,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n",
    "        X[j,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n",
    " #       y[j,:,:] = cv2.resize(seg[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n",
    "        \n",
    "  #  model.evaluate(x=X,y=y[:,:,:,0], callbacks= callbacks)\n",
    "    return model.predict(X/np.max(X), verbose=1)\n",
    "\n",
    "\n",
    "def showPredictsById(case, start_slice = 60):\n",
    "    path = f\"../input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_{case}\"\n",
    "    gt = nib.load(os.path.join(path, f'BraTS20_Training_{case}_seg.nii')).get_fdata()\n",
    "    origImage = nib.load(os.path.join(path, f'BraTS20_Training_{case}_flair.nii')).get_fdata()\n",
    "    p = predictByPath(path,case)\n",
    "\n",
    "    core = p[:,:,:,1]\n",
    "    edema= p[:,:,:,2]\n",
    "    enhancing = p[:,:,:,3]\n",
    "\n",
    "    plt.figure(figsize=(18, 50))\n",
    "    f, axarr = plt.subplots(1,6, figsize = (18, 50)) \n",
    "\n",
    "    for i in range(6): # for each image, add brain background\n",
    "        axarr[i].imshow(cv2.resize(origImage[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE)), cmap=\"gray\", interpolation='none')\n",
    "    \n",
    "    axarr[0].imshow(cv2.resize(origImage[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE)), cmap=\"gray\")\n",
    "    axarr[0].title.set_text('Original image flair')\n",
    "    curr_gt=cv2.resize(gt[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE), interpolation = cv2.INTER_NEAREST)\n",
    "    axarr[1].imshow(curr_gt, cmap=\"Reds\", interpolation='none', alpha=0.3) # ,alpha=0.3,cmap='Reds'\n",
    "    axarr[1].title.set_text('Ground truth')\n",
    "    axarr[2].imshow(p[start_slice,:,:,1:4], cmap=\"Reds\", interpolation='none', alpha=0.3)\n",
    "    axarr[2].title.set_text('all classes')\n",
    "    axarr[3].imshow(edema[start_slice,:,:], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n",
    "    axarr[3].title.set_text(f'{SEGMENT_CLASSES[1]} predicted')\n",
    "    axarr[4].imshow(core[start_slice,:,], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n",
    "    axarr[4].title.set_text(f'{SEGMENT_CLASSES[2]} predicted')\n",
    "    axarr[5].imshow(enhancing[start_slice,:,], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n",
    "    axarr[5].title.set_text(f'{SEGMENT_CLASSES[3]} predicted')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "showPredictsById(case=test_ids[0][-3:])\n",
    "showPredictsById(case=test_ids[1][-3:])\n",
    "showPredictsById(case=test_ids[2][-3:])\n",
    "showPredictsById(case=test_ids[3][-3:])\n",
    "showPredictsById(case=test_ids[4][-3:])\n",
    "showPredictsById(case=test_ids[5][-3:])\n",
    "showPredictsById(case=test_ids[6][-3:])\n",
    "\n",
    "\n",
    "# mask = np.zeros((10,10))\n",
    "# mask[3:-3, 3:-3] = 1 # white square in black background\n",
    "# im = mask + np.random.randn(10,10) * 0.01 # random image\n",
    "# masked = np.ma.masked_where(mask == 0, mask)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.imshow(im, 'gray', interpolation='none')\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.imshow(im, 'gray', interpolation='none')\n",
    "# plt.imshow(masked, 'jet', interpolation='none', alpha=0.7)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf907cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "case = case=test_ids[3][-3:]\n",
    "path = f\"../input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_{case}\"\n",
    "gt = nib.load(os.path.join(path, f'BraTS20_Training_{case}_seg.nii')).get_fdata()\n",
    "p = predictByPath(path,case)\n",
    "\n",
    "\n",
    "core = p[:,:,:,1]\n",
    "edema= p[:,:,:,2]\n",
    "enhancing = p[:,:,:,3]\n",
    "\n",
    "\n",
    "i=40 # slice at\n",
    "eval_class = 2 #     0 : 'NOT tumor',  1 : 'ENHANCING',    2 : 'CORE',    3 : 'WHOLE'\n",
    "\n",
    "\n",
    "\n",
    "gt[gt != eval_class] = 1 # use only one class for per class evaluation \n",
    "\n",
    "resized_gt = cv2.resize(gt[:,:,i+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "plt.figure()\n",
    "f, axarr = plt.subplots(1,2) \n",
    "axarr[0].imshow(resized_gt, cmap=\"gray\")\n",
    "axarr[0].title.set_text('ground truth')\n",
    "axarr[1].imshow(p[i,:,:,eval_class], cmap=\"gray\")\n",
    "axarr[1].title.set_text(f'predicted class: {SEGMENT_CLASSES[eval_class]}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e75c15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema, dice_coef_enhancing] )\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(test_generator, batch_size=100, callbacks= callbacks)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
